# app/telegram_bot/handlers/story_handler.py

import os
import openai
from aiogram import Router
from aiogram.types import Message

router = Router()
openai.api_key = os.getenv("OPENAI_API_KEY")
story_state = {}

def generate_continuation(prompt: str) -> str:
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "‘¥’∏÷Ç ’∫’°’ø’¥’∏’≤ ’•’Ω, ’∏÷Ä’® ’Ω’ø’•’≤’Æ’°’£’∏÷Ä’Æ ’∑’°÷Ä’∏÷Ç’∂’°’Ø’∏÷Ç’¥ ’ß ’∫’°’ø’¥’∏÷Ç’©’µ’∏÷Ç’∂’∂’•÷Ä’®÷â"},
                {"role": "user", "content": f"’á’°÷Ä’∏÷Ç’∂’°’Ø’´÷Ä ’°’µ’Ω ’∫’°’ø’¥’∏÷Ç’©’µ’∏÷Ç’∂’®’ù {prompt}"},
            ],
            max_tokens=300,
            temperature=0.9,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"‚ùå GPT ’Ω’≠’°’¨’ù {e}"

@router.message(lambda msg: msg.text == "‚úçÔ∏è ’á’°÷Ä’∏÷Ç’∂’°’Ø’´÷Ä ’∫’°’ø’¥’∏÷Ç’©’µ’∏÷Ç’∂’®")
async def ask_for_story(message: Message):
    story_state[message.from_user.id] = True
    await message.answer("üìú ‘≥÷Ä’´÷Ä ’∫’°’ø’¥’∏÷Ç’©’µ’°’∂ ’Ω’Ø’´’¶’¢’®, ÷á ’•’Ω ’°’µ’∂ ’Ø’∑’°÷Ä’∏÷Ç’∂’°’Ø’•’¥ üß†")

@router.message()
async def handle_story(message: Message):
    user_id = message.from_user.id
    if story_state.get(user_id):
        prompt = message.text.strip()
        await message.answer("‚è≥ ’á’°÷Ä’∏÷Ç’∂’°’Ø’∏÷Ç’¥ ’•’¥ ’∫’°’ø’¥’∏÷Ç’©’µ’∏÷Ç’∂’®...")
        continuation = generate_continuation(prompt)
        await message.answer(f"üìñ ‘±’∞’° ’∑’°÷Ä’∏÷Ç’∂’°’Ø’∏÷Ç’©’µ’∏÷Ç’∂’®’ù\n\n{continuation}")
        story_state[user_id] = False
